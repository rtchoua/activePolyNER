\section{Introduction}
\label{sect:apner_introduction}


\logan{Are you sure you want to use materials science as the opening line? Maybe add a general sentence up top "data-intensive science is awesome, but requires accessible data. The development of new materials is a great example for such opportunities and needs in domain science. [I'm making these comments under the context that this will be a thesis chapter]}
Despite the large number of publications in materials science, the process of designing new materials is still one of trial and error.
The field of materials informatics aims to address this problem by combining large datasets and computational models to achieve targeted materials design and reduce time-to-market and development costs of new materials.
A large amount of such data already exists in unstructured text in the scientific literature, hence the need for materials information extraction.
\logan{Good intro paragraph. "Opportunity -> problem you are solving" in an inch of text}

There is a considerable amount of prior work in scientific facts extraction, notably in biomedicine. 
State-of-the-art methods often use hybrid rule-based, machine learning, and statistical techniques to extract entity names and relations from the literature~\cite{leaman2008banner,zeng2015survey}. 
While similar efforts have begun in materials science~\cite{hawizy2011chemicaltagger,rocktaschel2012chemspot,leaman2015tmchem,swain2016chemdataextractor}, the lack of available training data for new materials impedes rapid progress. \logan{Cite an Elsa paper?}
Instead, attempts to extract a new type of materials rely  on large, carefully annotated training
data tailored for this new target, often requiring some amount of in-depth domain knowledge.
For example, in the subfield of polymer science, scientists and engineers lack access to a freely available large database of polymers and their properties.

%\kyle{should cite our previous papers about polyNER. ANd change phrasing here to make it sound like polyner is now well established
%and what we are doing here is enhancing it with active learning. }
To address these challenges, we have designed polyNER, a system for generating training data for scientific NER using semi-supervised and active learning.
PolyNER uses natural language processing to produce sets of candidate entities;
experts then iteratively approve or reject candidates in small batches selected using an active learning approach;
the labels are used to train a series of context-based word vector classifiers after each iteration.
PolyNER's labels can also be used to train other machine learning models to leverage features beyond their context to recognize target entities.
The goal is
to substitute the labor-intensive processes of assembling a large
manually annotated corpus (and reduce costs) by using small numbers of carefully selected candidates to be labeled via focused expert input. 
In this paper, we seek to improve polyNER's performance in both the generation of candidate entities and the labeling process.
We experiment with different seed entities to generate candidates and tune the word embedding model parameters to increase the yield of actual scientific entities among candidates; we use active learning with maximum entropy uncertainty sampling and two different pools of unlabeled data to train classifiers and compare their learning rate after 5 iterations. 
\logan{"seed entities" is not a standard term, right? If it is not standard, maybe use something less metaphorical "ways to generate initial candidates for labeling"}
Using labels generated via active learning we train word vector classifiers and achieve NER performance comparable to 
a state-of-the art rule-based chemical entity extraction
system, ChemDataExtractor (CDE)~\cite{swain2016chemdataextractor}, which we have previously enhanced
with dictionary- and rule-based methods for identifying polymers~\cite{tchoua2017towards}.
Our system however, took less than five hours of expert time to achieve this result.


The rest of this paper is as follows. 
In Section~\ref{sect:background}, we motivate the need for identifying polymer names in
text. 
We review semi-supervised methods for NLP systems in
Section~\ref{sect:apner_related}. 
We describe the design and implementation in Section~\ref{sect:apner_architecture} and evaluate polyNER
in Section~\ref{sect:apner_results}. We summarize and discuss future work in Section~\ref{sect:apner_conclusion}.
\logan{<soapbox>I only see CS have this "table of contents" paragraph. Is it explicitly required, or just an idiosyncrasy of the CS community? Also, does everyone skip over them while reading anyway?</soapbox>}