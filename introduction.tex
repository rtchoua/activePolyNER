\section{Introduction}
\label{sect:apner_introduction}

%\kyle{readers will be confused of which domain you mean here? I think this first paragraph
%can be clearer and to the point.}
%\roselyne{I added the field right away, I thought this was the most to the point way of going into the motivation?}

Despite the large number of publications in materials science, the process of designing new materials is still one of trial and error.
The field of materials informatics aims to address this problem by combining large datasets and computational models to achieve targeted materials design and reduce time-to-market and development costs of new materials.
A large amount of such data already exists in unstructured text in the scientific literature, hence the need for materials information extraction.

There is a considerable amount of prior work in scientific facts extraction, notably in biomedicine. 
State-of-the-art methods often use hybrid rule-based, machine learning, and statistical techniques to extract entity names and relations from the literature~\cite{leaman2008banner,zeng2015survey}. 
While similar efforts have begun in materials science~\cite{hawizy2011chemicaltagger,rocktaschel2012chemspot,leaman2015tmchem,swain2016chemdataextractor}, the lack of available training data for new materials impedes rapid progress. 
Instead, attempts to extract a new type of materials rely  on large, carefully annotated training
data tailored for this new target, often requiring some amount of in-depth domain knowledge.
For example, in the subfield of polymer science, scientists and engineers lack access to a freely available large database of polymers and their properties.

To address these challenges, we propose polyNER, a system for generating training data for scientific NER using semi-supervised and active learning. 
PolyNER uses natural language processing to produce sets of candidate entities;
experts then iteratively approve or reject candidates in small batches selected using an active learning approach;
the labels are used to train a series of context-based word vector classifiers after each iteration.
PolyNER's labels can also be used to train other machine learning models to leverage features beyond their context to recognize target entities.
The goal is
to substitute the labor-intensive processes of assembling a large
manually annotated corpus (and reduce costs) by using small numbers of carefully selected candidates to be labeled via focused expert input. 
We use active learning with maximum entropy uncertainty sampling and two different pools of unlabeled data to train classifiers and compare their learning rate after 5 iterations. 
Using labels generated via active learning we train word vector classifiers and achieve NER performance comparable to 
a state-of-the art rule-based chemical entity extraction
system, ChemDataExtractor (CDE)~\cite{swain2016chemdataextractor}, which we have previously enhanced
with dictionary- and rule-based methods for identifying polymers~\cite{tchoua2017towards}.
Our system however, took less than five hours of expert time to achieve this result.
%\kyle{We talk here about identifying polymers but that specific problem hasnt been introduced}
%\roselyne{Thanks fixed it, right before challlenge.}
The rest of this paper is as follows. 
In Section~\ref{sect:background}, we motivate the need for identifying polymer names in
text. 
We review semi-supervised methods for NLP systems in
Section~\ref{sect:relatedwork}. 
We describe the design and implementation in Section~\ref{sect:architecture} and evaluate polyNER
in Section~\ref{sect:results}. We summarize and discuss future work in Section~\ref{sect:conclusion}.