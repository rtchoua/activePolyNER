\section{Conclusion}
\label{sect:apner_conclusion}
A lack of expert-annotated training data impedes the adoption of machine learning techniques in certain scientific applications.
PolyNER overcomes this challenge by 
using active learning to target 
expert input so that accurate scientific named entity recognition can be performed at low cost.
We show that by using NLP techniques, we can bootstrap a word vector classifier of scientific entities.
Using polyNER's labels and a classifier of character-enhanced word embedding vectors, we achieve 
%achieves 31.7\% precision and 82.3\% recall,  a 
performance comparable to a best-of-breed
%\loganfussingaboutrecallandprecision \roselyne{came with PR curve showing good trade off margins}
hybrid NER model (CDE+) that required much expert development.
%\logan{Very long sentence, break it up.}
In contrast, polyNER was trained on data annotated using just five hours of expert time and a little untrained crowd input.
%\logan{This is your most important conclusion, perhaps bring it earlier in the conclusion}
%\ian{Is it important to have the phrase ``While we note that CDE+ is intended to extract polymers and their properties,''?}
%While we note that CDE+ is intended to extract polymers and their properties, 
Our work highlights the potential for using minimal labeled data %\ian{``minimal data'': do you mean ``minimal labeled data''?}\roselyne{yes}
and focused expert input to enable machine learning techniques for previously unmined scientific entities. 
We are currently exploring using polyNER-labeled data to annotate text for other NER approaches,
such as bidirectional long short-term memory models. This dataset will soon be available on DLHub~\cite{chard2018dlhub} for the public to use for training of machine learning models.
Such resources can be used along with other databases and dictionaries such as PPPDB~\footnote{Polymer Property Predictor and Database: https://pppdb.uchicago.edu/} and Khazana~\cite{huan2016polymer} for validation purposes. 
%\logan{Also, spell out your recommended best practices for building a new NER model. Either here or in the discussion if it would take too much text for a conclusion}\roselyne{I think this is partly addressed with the diversity discussion but I will add and summarize main thoughts there}
%We also plan to explore the generalizability of our approach further by applying it extracting previously unmined scientific entities in other fields.
We will also formally explore the hybrid-computer partnership as an optimization problem.
In other words, we will work on a more
rigorous approach to automatic partitioning and assignment of extraction tasks in order to maximize the accuracy of extracted data while minimizing the time and cost of human involvement.

%With a view to exploring generalizability, we are also working to apply polyNER
%to quite different problems, such as extracting dataset names from social science
%literature. 
%\logan{Maybe be a little more broad here. "We hope that our findings will ...", etc.}\roselyne{this is also too close to previous conclusion, hadn't worked on it enough yet}
